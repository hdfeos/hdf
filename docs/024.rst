==================
HDF Newsletter #24
==================

To subscribe/unsubscribe to the hdfnews mailing list, please send your
request to ncsalist@ncsa.uiuc.edu with the appropriate command (e.g.
subscribe hdfnews, unsubscribe hdfnews, help) in the *body* of the message.

-------------------------------------------------------------------------------



 Newsletter #24
 February 24, 1997

CONTENTS

. HDF 4.1 Release 1
 A. New Features and Changes *******************************
 B. Platforms Tested * Visit the HDF home page *
 C. Known Problems * for up-to-date information *
 D. Important Fixes * on HDF: *

 * http://hdf.ncsa.uiuc.edu/ *

. New Additions to the HDF Group *******************************
. HDFNOW

- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

HDF 4.1 Release 1
=================

HDF 4.1 Release 1 is now available on the NCSA anonymous ftp server
(ftp.ncsa.uiuc.edu) in the directory HDF/HDF_Current/. The HDF 4.0r2
release has been placed under HDF/prev_releases.

A. New Features and Changes:

o Attributes are now supported in both the vdata and vgroup
 APIs. In the vdata API, attributes can be attached to either
 vdata fields or vdatas; in the vgroup API, attributes can be
 attached to vgroups. This new functionality can be used
 to attach attributes to vdatas and vgroups created by earlier
 versions of the HDF library. However, the old versions of
 the HDF library cannot read the new version vdatas and vgroups.
 A vdata/vgroup having attributes will become a new version
 vdata/vgroup. For more information, please refer to the file
 ../release_notes/vattr.txt, the man pages for the new functions,
 and the HDF 4.1 User's Guide.

o Data chunking is now supported in SD scientific data sets.
 When data chunking is used, an n-dimensional SDS is stored
 as a series of n-dimensional chunks, improving performance on
 certain types of partial read operations.

 New routines for creating and manipulating chunked SD
 scientific data sets have been provided, and two preexisting
 SD I/O routines, SDreaddata and SDwritedata, have also been
 modified to work with chunked SDSs. For more information, please
 refer to the file ../release_notes/sd_chunk_examples.txt, the
 man page for sd_chunk, and the HDF 4.1 User's Guide.

o Due to certain limitations in the way compressed SDS datasets are stored,
 data which has been compressed is not completely writable in ways that
 uncompressed datasets are. The "rules" for writing to a compressed
 dataset are as follows:

 (1) Write an entire dataset that is to be compressed. i.e. build the
 dataset entirely in memory, then write it out with a single call.

 (2) Append to a compressed dataset. i.e. write to a compressed dataset
 that has already been written out by adding to the unlimited
 dimension for that dataset.

 (3) For users of HDF 4.1, write to any subset of a compressed dataset
 that is also chunked.

 Please refer to the HDF 4.1 User's Guide for more information.

o HDF now creates free format FORTRAN include files. In order to make
 FORTRAN 90 programs be able to use HDF include files (*.inc), HDF4.1r1
 creates F90 versions of these files during the 'make' process on UNIX
 platforms, by replacing 'C' or 'c' in column 1 with '!'. Continuation
 lines in hdf.inc have been eliminated. The F90 version files are named
 as hdf.f90, dffunc.f90 and netcdf.f90.

o Several performance improvements have been added. Test programs on SPARC
 20/Solaris 2.5 show that when creating an hdf file with 2500 3D (10x10x10)

.. code-block:: fortran

    float32 SDSs, the program execution speed is improved by 2.5 - 4.8 times,
    and SDend is faster by 4.3 - 20 times.


o A new function, SDsetfillmode, has been added. It can be used to prevent
 SDwritedata from pre-filling the dataset with a user defined or default
 fill value, so that better performance can be obtained.

o SGI has changed some compiler default settings in IRIX 6.2.
 We decided to explicitly define the settings of various ABI related

.. code-block:: c

    options. For the 64 bit OS ("uname -s" returns IRIX64), HDF uses
    "-64 -mips4" code. For the traditional 32 bit OS ("uname -s" returns
    IRIX), HDF uses "-32 -mips2". To use n32 mode on IRIX64, HDF uses
    "-n32 -mips3" code. Note that in the previous release (4.0r2), HDF
    used only "-n32". In IRIX 6.1 and before, "-n32" defaulted to
    "-mips4" code but in IRIX 6.2, it defaults to mips3 or mips4 code.
    We decided to explicitly set it to "-n32 -mips3". Therefore,
    applications linking with the HDF library must be compiled with
    the same explicit ABI options.


o This will be the last release that we support the CM5.

 HDF 4.1 Beta 1 USERS ONLY

-------------------------------------------------------------------------------


o The SD chunking routine names were changed to be more consistent
 with the SD interface. The names of the routines are now in lower

.. code-block:: fortran

    case, after the two initial "SD" characters. For example,
    SDwriteChunk() has been changed to SDwritechunk().


o The _HDF_ENTIRE_VDATA variable has been changed to _HDF_VDATA.
 For those users already using it, a macro called _HDF_ENTIRE_VDATA
 has been added, which is defined as _HDF_VDATA.

o You can now create an empty compressed SDS.

 Please refer to the ../release_notes/bugs_fixed.txt file for changes
 in this release.

B. Platforms Tested:

HDF 4.1 Release 1 has been tested on the following platforms:

 CM5 Parallel I/O 4.1.3_U1
 DEC Alpha/Digital Unix 3.2
 DEC Alpha/OpenVMS AXP 6.2 (not available yet)
 DEC VAX OpenVMS 6.2 (not available yet)
 Exemplar 9.03
 FreeBSD 2.2
 HP-UX 9.03
 HP-UX 10.10
 IRIX 5.3
 IRIX 6.2_64
 IRIX 6.2_n32
 IRIX 6.4_64
 IRIX 6.4_n32
 Linux A.OUT 1.2.4
 Linux ELF 2.0.27 (C only)
 Macintosh PowerPC (C only) (not available yet)
 SP2 4.1
 Solaris 2.5
 Solaris_x86 2.5
 SunOS 4.1.3
 Windows NT/95 (C only) (not available yet)

C. Known Problems:

o With the SD interface, you are unable to overwrite
 existing compressed data, that is not stored in
 "chunked" form. This is due to compression algorithms
 not being suitable for "local" modifications in a compressed
 datastream.

.. code-block:: c

   o There are no plans to add the DF24writeref function
    to the DF24 interface. This function will be removed
    from the documentation.


D. Important Fixes:

o If you opened a file in Read Only mode with the SD interface
 (using SDstart), it would create the file if the file did not
 exist. This no longer occurs.

o HDF 4.0r2 did not recognize JPEG images created by HDF 3.3r4.
 This has been fixed.

See the ../release_notes/bug_fixed.txt file for more information
on bugs fixed in this release.


New Additions to the HDF Group

-------------------------------------------------------------------------------


Welcome to three new HDFers:

Tammi O'Neill joins us as the HDF group's new administrative
assistant. Tammi has worked at the university (U of I) and in
industry, and we are hoping she will help us finally get ourselves
organized!

Elena Pourmal joins us from the U of I MRL lab as a research
developer. She will be helping us develop our QA department,
and has an extensive background in Fortran and VMS.

Apu Kapadia is a U of I student helping Xinjian Lu to implement
the capability of transferring large datasets in habanero, when using
the Java-based HDF Viewer.


HDFNOW
======
You may have noticed the announcement regarding HDFNOW (HDF Network of
Workstations), which was sent earlier to the hdfnews mailing list. This
project is a big step in extending HDF to support parallel I/O. It was
written for those familiar with the SD interface and experienced with
message-passing programs.

For more information, take a look at the Parallel_HDF home page at:
 http://hdf.ncsa.uiuc.edu/Parallel_HDF/parallel_hdf.html
